from llm_interface.llm_client import LLMClient

class Summarizer:
    def __init__(self):
        # Initialize LLMClient in OpenAI mode with the specified model
        self.llm = LLMClient(mode='openai', summarizer_model_name='gpt-4o-mini')

    def summarize_command_output(self, command, output, previous_summary=""):
        """
        Summarizes the output of a command during a penetration test.
        
        Parameters:
        - command: The penetration test command executed.
        - output: The output generated by executing the command.
        - previous_summary: The previous summary of activities (optional).
        
        Returns:
        - Updated summary with the new information incorporated.
        """
        prompt = f"""You are summarizing the output of a command during a penetration test.

Previous summary:
{previous_summary if previous_summary else "None"}

New command:
{command}

Command output:
{output}

Update the summary to include this new information. Keep it concise and relevant to the penetration test progress."""
        
        # Request the summary update from the LLM
        return self.llm.query_summarizer(prompt, max_tokens=300)
