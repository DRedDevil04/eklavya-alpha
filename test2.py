import os
from langchain_community.llms import LlamaCpp
from interface.connector import SSHConnector

# Load Local Model (Update path if needed)
llm = LlamaCpp(model_path="/home/bhagat/.lmstudio/models/PrunaAI/mistralai-Mistral-7B-Instruct-v0.2-GGUF-smashed/Mistral-7B-Instruct-v0.2.Q4_K_S.gguf")

# Create SSH session
ssh = SSHConnector("192.168.122.186", "kali", "kali")
ssh.create_ssh_session()

# Initial instruction message
system_prompt = (
    "You are an AI assisting in penetration testing. You have SSH access to a Kali machine. "
    "Generate a single valid Linux command to find and attack hosts accordingly. "
    "Only return a bash command that can be executed directly on Kali Linux. "
    "Do not include explanations or additional text. "
    "Do not use placeholders like 'ip'‚Äîfind everything out as an attacker would. "
    "The first infected node IP is 192.168.122.12, and its root password is 'ubuntu'. "
    "SSH into the first node and read flag.txt in the root home directory. "
    "Do not use markdown formatting, code blocks, or any explanations. Only output the raw command."
    "REMOVE MARKDOWN FORMATTING IN FINAL OUTPUT , GIVE ONLY RAW COMMAND"
)

# Start chat with the local model
messages = [system_prompt]
print("üîç Running Penetration Testing AI...\n")

while True:
    # Get command suggestion from LLM
    command = llm.invoke("\n".join(messages)).strip()
    print(f"\nGenerated Command: {command}")

    # Execute command via SSH
    output = ssh.execute_command(command)
    print(f"\nCommand Output:\n{output}")

    # Stop execution if flag.txt is found
    if "flag.txt" in output.lower() or "flag{" in output.lower():
        print("\nüèÅ Flag found! Stopping penetration test.")
        break

    # Append to conversation history
    messages.append(command)
    messages.append(output)
